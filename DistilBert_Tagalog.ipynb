{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb9c040512ee400486dc0b2265e8762e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3a398687ade406b843f36ad95bd837d",
              "IPY_MODEL_89eee6d73a934ba1895451cde759548b",
              "IPY_MODEL_d6d0fb8f78074441b4d9678697d6e036"
            ],
            "layout": "IPY_MODEL_25526d04359645b686734b0a9fc820fd"
          }
        },
        "d3a398687ade406b843f36ad95bd837d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698ba11f760b4a14a0ebaac123efc9c1",
            "placeholder": "​",
            "style": "IPY_MODEL_1874645353e04a1fbf11a38bf2e97b80",
            "value": "Map: 100%"
          }
        },
        "89eee6d73a934ba1895451cde759548b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b28ed321c05e4ceab04914672b7377d8",
            "max": 36,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c6117b48860402db1e04c10527fd1b9",
            "value": 36
          }
        },
        "d6d0fb8f78074441b4d9678697d6e036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e48fb0be39b4545a60f50a1cea92b55",
            "placeholder": "​",
            "style": "IPY_MODEL_a93fc20e25dd4ba3a9ac58f0d0b8fa01",
            "value": " 36/36 [00:00&lt;00:00, 918.35 examples/s]"
          }
        },
        "25526d04359645b686734b0a9fc820fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698ba11f760b4a14a0ebaac123efc9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1874645353e04a1fbf11a38bf2e97b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b28ed321c05e4ceab04914672b7377d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c6117b48860402db1e04c10527fd1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e48fb0be39b4545a60f50a1cea92b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a93fc20e25dd4ba3a9ac58f0d0b8fa01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0ba98681ff24d879c93adfc3b08278a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a98008eb7174b119cbe084b866bae5c",
              "IPY_MODEL_ea6a0ca473e24569bde16cca65a4a072",
              "IPY_MODEL_80e84a1fa75247ad86f3b5ecff53d9fb"
            ],
            "layout": "IPY_MODEL_8ce0263a93f34d7c818c47c4100acd88"
          }
        },
        "9a98008eb7174b119cbe084b866bae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4697c0ef08548c18332c2661fd11e0e",
            "placeholder": "​",
            "style": "IPY_MODEL_52b3cf0d7f594977b96c79c66f37e8d3",
            "value": "Map: 100%"
          }
        },
        "ea6a0ca473e24569bde16cca65a4a072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ae539eec75494aab4fc5852ebcb47d",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d92d3c3001514be19e458219c1545d0f",
            "value": 9
          }
        },
        "80e84a1fa75247ad86f3b5ecff53d9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09c83b5b2c834eb68a3dfeb962104166",
            "placeholder": "​",
            "style": "IPY_MODEL_01ad820092c34961aa7f8a7dfbc26abd",
            "value": " 9/9 [00:00&lt;00:00, 192.50 examples/s]"
          }
        },
        "8ce0263a93f34d7c818c47c4100acd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4697c0ef08548c18332c2661fd11e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b3cf0d7f594977b96c79c66f37e8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5ae539eec75494aab4fc5852ebcb47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92d3c3001514be19e458219c1545d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09c83b5b2c834eb68a3dfeb962104166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ad820092c34961aa7f8a7dfbc26abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "x2o_p9cA3Ver"
      },
      "outputs": [],
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('/content/sample_data', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DistilBERT Tagalog"
      ],
      "metadata": {
        "id": "9pxilJvf3okD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "import tempfile\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "_DQMTIDv3zpp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  IMPORT LIBRARIES AND SETUP"
      ],
      "metadata": {
        "id": "qtWm02vg31Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def install_requirements():\n",
        "    required_packages = [\n",
        "        'transformers[torch]',\n",
        "        'datasets',\n",
        "        'torch',\n",
        "        'pandas',\n",
        "        'scikit-learn',\n",
        "        'onnx',\n",
        "        'onnxruntime',\n",
        "        'optimum[onnxruntime]',  # This enables ORTModelForSequenceClassification\n",
        "        'tensorflow',\n",
        "    ]\n",
        "\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package.split('[')[0])\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
      ],
      "metadata": {
        "id": "O9CZzO3j37SH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking and installing dependencies...\")\n",
        "install_requirements()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE6M6HJb39Gi",
        "outputId": "e2cd1d0a-4265-4101-ad14-4c2e3262da73"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking and installing dependencies...\n",
            "Installing scikit-learn...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from optimum.onnxruntime import ORTModelForSequenceClassification\n",
        "    from optimum.onnxruntime.configuration import OptimizationConfig\n",
        "    ONNX_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Optimum ONNX Runtime not available, ONNX export will be limited\")\n",
        "    ONNX_AVAILABLE = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Eb-XVtQ3_cT",
        "outputId": "39a40d82-0488-495c-c6a8-67d5682ad32a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimum ONNX Runtime not available, ONNX export will be limited\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All dependencies loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1uxO2MU4BER",
        "outputId": "f759e857-6487-47cf-fb1e-acdd7f5e28ba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD AND PREPARE DATASET"
      ],
      "metadata": {
        "id": "rF1hqEwx4Cg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(csv_path='dataset.csv'):\n",
        "    print(f\"Loading dataset from {csv_path}...\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['text', 'label']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Clean and validate data\n",
        "        df = df.dropna(subset=['text', 'label'])\n",
        "        df['text'] = df['text'].astype(str)\n",
        "        df['label'] = df['label'].astype(int)\n",
        "\n",
        "        # Check label range\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        num_labels = len(unique_labels)\n",
        "\n",
        "        # Ensure labels are sequential starting from 0\n",
        "        if unique_labels != list(range(num_labels)):\n",
        "            print(\"Warning: Labels are not sequential starting from 0. Remapping...\")\n",
        "            label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "            df['label'] = df['label'].map(label_mapping)\n",
        "            print(f\"Label mapping: {label_mapping}\")\n",
        "\n",
        "        print(f\"Dataset validation complete. Clean shape: {df.shape}\")\n",
        "        print(f\"Number of classes: {num_labels}\")\n",
        "        print(f\"Label distribution:\\n{df['label'].value_counts().sort_index()}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file '{csv_path}' not found!\")\n",
        "        print(\"Creating a sample Tagalog dataset for demonstration...\")\n",
        "        return create_sample_dataset()"
      ],
      "metadata": {
        "id": "or0KXVIe4GCV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_dataset():\n",
        "    sample_data = {\n",
        "        'text': [\n",
        "            # Positive sentiment (label 0) - Tagalog\n",
        "            'Napakaganda ng produktong ito, sulit na sulit!',\n",
        "            'Sobrang galing ng serbisyo nila, highly recommended!',\n",
        "            'Magandang kalidad at mabilis na delivery.',\n",
        "            'Napakahusay ng customer support, user-friendly pa.',\n",
        "            'Outstanding performance at great value for money.',\n",
        "            'Masarap ang pagkain dito, babalik ako ulit.',\n",
        "            'Magaling ang mga empleyado, napakabait.',\n",
        "            'Sulit ang binayad ko, satisfied ako sa quality.',\n",
        "            'Excellent ang service, walang reklamo.',\n",
        "            'Napakaganda ng lugar, perfect para sa family.',\n",
        "            'Masayang experience, hindi ako nagsisi.',\n",
        "            'Mataas ang kalidad, worth it ang presyo.',\n",
        "            'Napakabilis ng delivery, thank you!',\n",
        "            'Sobrang ganda ng design, modern pa.',\n",
        "            'Napakasarap ng lasa, uulitin ko to.',\n",
        "\n",
        "            # Neutral sentiment (label 1) - Tagalog\n",
        "            'Okay lang ang produkto, walang masama.',\n",
        "            'Average lang ang kalidad, sakto sa presyo.',\n",
        "            'Gumagana naman, walang problema.',\n",
        "            'Standard features, typical sa price range na to.',\n",
        "            'Normal lang ang delivery time, okay naman.',\n",
        "            'Hindi masama, hindi rin maganda.',\n",
        "            'Pwede na, sulit naman sa presyo.',\n",
        "            'Okay lang ang service, walang special.',\n",
        "            'Hindi ako disappointed, hindi rin excited.',\n",
        "            'Sakto lang, meets expectations.',\n",
        "            'Average ang lasa, hindi masama.',\n",
        "            'Okay ang quality, walang problema.',\n",
        "            'Standard lang ang service, normal.',\n",
        "            'Hindi special pero okay naman.',\n",
        "            'Pwede na, acceptable naman.',\n",
        "\n",
        "            # Negative sentiment (label 2) - Tagalog\n",
        "            'Sobrang pangit ng produkto, sayang ang pera.',\n",
        "            'Mababa ang kalidad, nasira agad after one day.',\n",
        "            'Napakasama ng customer service, worst ever.',\n",
        "            'Sobrang bagal ng delivery at sira pa ang packaging.',\n",
        "            'Hindi ko irerekumenda, very disappointing.',\n",
        "            'Terrible ang experience, hindi sulit.',\n",
        "            'Pangit ang lasa, hindi ko naubos.',\n",
        "            'Mahal tapos pangit pa ang kalidad.',\n",
        "            'Sobrang tagal ng antay, nainis ako.',\n",
        "            'Hindi maganda ang service, rude pa ang staff.',\n",
        "            'Nasira agad, walang kwentang produkto.',\n",
        "            'Masamang experience, hindi ako babalik.',\n",
        "            'Sobrang disappointing, sayang ang time.',\n",
        "            'Pangit ang quality control, maraming defects.',\n",
        "            'Hindi worth it ang presyo, panget pa.',\n",
        "        ],\n",
        "        'label': (\n",
        "            [0] * 15 +  # Positive samples\n",
        "            [1] * 15 +  # Neutral samples\n",
        "            [2] * 15    # Negative samples\n",
        "        )\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    df.to_csv('dataset.csv', index=False)\n",
        "    print(\"Sample Tagalog sentiment dataset created and saved as 'dataset.csv'\")\n",
        "    print(\"Dataset includes various Tagalog text samples for sentiment classification\")\n",
        "    print(\"Labels: 0=Positive, 1=Neutral, 2=Negative\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "bgXGIhhO4K4a"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(df, test_size=0.2, random_state=42):\n",
        "    print(f\"Splitting dataset: {test_size*100}% for validation...\")\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        df['text'].tolist(),\n",
        "        df['label'].tolist(),\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=df['label']\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Validation set: {len(X_val)} samples\")\n",
        "\n",
        "    return X_train, X_val, y_train, y_val"
      ],
      "metadata": {
        "id": "O5su8nsY4OGH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZATION AND PREPROCESSING"
      ],
      "metadata": {
        "id": "ZHauHEU04Pe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokenized_datasets(X_train, X_val, y_train, y_val, model_name):\n",
        "    \"\"\"Tokenize the datasets using the DistilBERT Tagalog tokenizer\"\"\"\n",
        "    print(\"Loading DistilBERT Tagalog tokenizer and creating tokenized datasets...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # DistilBERT uses BERT-style tokenization\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.unk_token if tokenizer.unk_token is not None else '[PAD]'\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = Dataset.from_dict({\n",
        "        'text': X_train,\n",
        "        'labels': y_train\n",
        "    })\n",
        "\n",
        "    val_dataset = Dataset.from_dict({\n",
        "        'text': X_val,\n",
        "        'labels': y_val\n",
        "    })\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            truncation=True,\n",
        "            padding=False,  # Will be handled by data collator\n",
        "            max_length=256  # Increased for Tagalog text which can be longer\n",
        "        )\n",
        "\n",
        "    # Tokenize datasets\n",
        "    train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
        "    val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    print(\"Tokenization complete!\")\n",
        "    print(f\"Sample tokenized text length: {len(train_tokenized[0]['input_ids'])}\")\n",
        "\n",
        "    return train_tokenized, val_tokenized, tokenizer"
      ],
      "metadata": {
        "id": "kuBDe6r94R2K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING"
      ],
      "metadata": {
        "id": "F-5Qq3hI4TmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataset, val_dataset, tokenizer, model_name, output_dir, num_labels):\n",
        "    \"\"\"Train the DistilBERT Tagalog model for classification\"\"\"\n",
        "    print(\"Initializing DistilBERT Tagalog model for classification training...\")\n",
        "\n",
        "    # Load model with appropriate number of labels\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_labels,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "\n",
        "    # Ensure model uses the correct pad_token_id\n",
        "    if tokenizer.pad_token_id is not None:\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    # Training arguments optimized for DistilBERT Tagalog\n",
        "    training_args_dict = {\n",
        "        'output_dir': output_dir,\n",
        "        'num_train_epochs': 3,  # Standard epochs for DistilBERT\n",
        "        'per_device_train_batch_size': 8,  # Smaller batch size (DistilBERT is larger than XtremeDistil)\n",
        "        'per_device_eval_batch_size': 8,\n",
        "        'learning_rate': 3e-5,  # Standard learning rate for DistilBERT\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_ratio': 0.1,\n",
        "        'logging_dir': f'{output_dir}/logs',\n",
        "        'logging_steps': 10,\n",
        "        'save_total_limit': 2,\n",
        "        'load_best_model_at_end': True,\n",
        "        'metric_for_best_model': \"eval_f1_macro\",\n",
        "        'greater_is_better': True,\n",
        "        'report_to': [],\n",
        "        'seed': 42,\n",
        "        'dataloader_num_workers': 0,\n",
        "        'remove_unused_columns': True,\n",
        "        'fp16': True,  # Mixed precision for efficiency\n",
        "        'dataloader_pin_memory': False,\n",
        "        'gradient_checkpointing': True,  # Enable for memory efficiency\n",
        "    }\n",
        "\n",
        "    # Add version-specific parameters\n",
        "    if hasattr(TrainingArguments, 'eval_strategy'):\n",
        "        training_args_dict['eval_strategy'] = \"epoch\"\n",
        "        training_args_dict['save_strategy'] = \"epoch\"\n",
        "    else:\n",
        "        training_args_dict['evaluation_strategy'] = \"epoch\"\n",
        "        training_args_dict['save_strategy'] = \"epoch\"\n",
        "\n",
        "    training_args = TrainingArguments(**training_args_dict)\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "\n",
        "        # Handle different prediction formats\n",
        "        if isinstance(predictions, tuple):\n",
        "            predictions = predictions[0]\n",
        "\n",
        "        # Convert to numpy array if it's a tensor\n",
        "        if hasattr(predictions, 'numpy'):\n",
        "            predictions = predictions.numpy()\n",
        "\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        f1_macro = f1_score(labels, predictions, average='macro')\n",
        "        f1_weighted = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "        }\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the best model\n",
        "    print(f\"Saving model to {output_dir}...\")\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    return trainer, model"
      ],
      "metadata": {
        "id": "cfaS6-MT4X_A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL EVALUATION"
      ],
      "metadata": {
        "id": "LTugezdq4bCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the evaluate_model function with this corrected version\n",
        "def evaluate_model(trainer, X_val, y_val, output_dir, num_labels):\n",
        "    print(\"Evaluating model performance...\")\n",
        "    import torch\n",
        "    # Get predictions\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Get detailed predictions for classification report\n",
        "    predictions = trainer.predict(trainer.eval_dataset)\n",
        "\n",
        "    # Extract predictions from the prediction object\n",
        "    if hasattr(predictions, 'predictions'):\n",
        "        preds = predictions.predictions\n",
        "    else:\n",
        "        preds = predictions[0]\n",
        "\n",
        "    # Handle tuple output (logits, other outputs)\n",
        "    if isinstance(preds, tuple):\n",
        "        # Take the first element which should be the logits\n",
        "        preds = preds[0]\n",
        "\n",
        "    # Convert to numpy array if it's a tensor\n",
        "    if hasattr(preds, 'numpy'):\n",
        "        preds = preds.numpy()\n",
        "    elif torch.is_tensor(preds):\n",
        "        preds = preds.cpu().numpy()\n",
        "\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Generate classification report\n",
        "    if num_labels == 2:\n",
        "        target_names = ['Safe', 'NSFW']\n",
        "    elif num_labels == 3:\n",
        "        target_names = ['Positive', 'Neutral', 'Negative']\n",
        "    else:\n",
        "        target_names = [f'Class_{i}' for i in range(num_labels)]\n",
        "\n",
        "    report = classification_report(\n",
        "        y_val,\n",
        "        y_pred,\n",
        "        target_names=target_names,\n",
        "        digits=4\n",
        "    )\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_val, y_pred, average='weighted')\n",
        "\n",
        "    # Prepare metrics text\n",
        "    metrics_text = f\"\"\"DistilBERT Tagalog Classification Model Evaluation Results\n",
        "{'='*70}\n",
        "\n",
        "Model: jcblaise/distilbert-tagalog-base-cased\n",
        "Task: Tagalog Text Classification ({num_labels} classes)\n",
        "Architecture: DistilBERT (6 layers, 768 hidden units) - Tagalog optimized\n",
        "\n",
        "Performance Metrics:\n",
        "{'-'*30}\n",
        "Accuracy: {accuracy:.4f}\n",
        "F1-Score (Macro): {f1_macro:.4f}\n",
        "F1-Score (Weighted): {f1_weighted:.4f}\n",
        "\n",
        "Classification Report:\n",
        "{report}\n",
        "\n",
        "Training Results:\n",
        "{'-'*30}\n",
        "\"\"\"\n",
        "\n",
        "    for key, value in eval_results.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            metrics_text += f\"{key}: {value:.4f}\\n\"\n",
        "\n",
        "    # Save metrics\n",
        "    os.makedirs('metrics', exist_ok=True)\n",
        "    metrics_path = 'metrics/distilbert_tagalog_metrics.txt'\n",
        "\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        f.write(metrics_text)\n",
        "\n",
        "    print(f\"Metrics saved to {metrics_path}\")\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
        "\n",
        "    return accuracy, report"
      ],
      "metadata": {
        "id": "asxLzV8M4fCf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX EXPORT"
      ],
      "metadata": {
        "id": "jdhyzmho4iYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_onnx(model_dir, onnx_path):\n",
        "    print(\"Exporting DistilBERT Tagalog model to ONNX format...\")\n",
        "\n",
        "    try:\n",
        "        # Load the trained model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "        # Create dummy input with Tagalog sample\n",
        "        dummy_input = tokenizer(\n",
        "            \"Ito ay isang sample na Tagalog text para sa ONNX export\",\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=256,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        # Export to ONNX with optimization for DistilBERT\n",
        "        os.makedirs(os.path.dirname(onnx_path), exist_ok=True)\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            tuple(dummy_input.values()),\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=14,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input_ids', 'attention_mask'],\n",
        "            output_names=['logits'],\n",
        "            dynamic_axes={\n",
        "                'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
        "                'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
        "                'logits': {0: 'batch_size'}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "        print(f\"ONNX model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ONNX export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "16e_aAsH4lVl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSORFLOW LITE EXPORT"
      ],
      "metadata": {
        "id": "LrD6ndRr4pWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_tflite_from_pt(model_dir, tflite_path):\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "        print(\"Converting DistilBERT Tagalog PyTorch model to TensorFlow...\")\n",
        "\n",
        "        # Load and convert to TensorFlow\n",
        "        tf_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "            model_dir,\n",
        "            from_pt=True\n",
        "        )\n",
        "\n",
        "        # Save as TensorFlow SavedModel\n",
        "        tf_saved_model_dir = os.path.join(model_dir, \"tf_saved_model\")\n",
        "        tf.saved_model.save(tf_model, tf_saved_model_dir)\n",
        "        print(f\"Saved intermediate TensorFlow model to {tf_saved_model_dir}\")\n",
        "\n",
        "        # Convert to TFLite with optimizations\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_saved_model_dir)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "        # Additional optimizations for mobile deployment\n",
        "        converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save TFLite model\n",
        "        os.makedirs(os.path.dirname(tflite_path), exist_ok=True)\n",
        "        with open(tflite_path, \"wb\") as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"TFLite model successfully exported to: {tflite_path}\")\n",
        "        print(f\"TFLite model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow Lite export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "74jZt0eL4r9z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "Ki11Jbfq4u9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Starting DistilBERT Tagalog Text Classification Pipeline\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Configuration - Updated to use DistilBERT Tagalog model\n",
        "    MODEL_NAME = \"jcblaise/distilbert-tagalog-base-cased\"\n",
        "    OUTPUT_DIR = \"models/distilbert_tagalog_classification\"\n",
        "    ONNX_PATH = \"models/distilbert_tagalog_classification_model.onnx\"\n",
        "    TFLITE_PATH = \"models/distilbert_tagalog_classification_model.tflite\"\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    os.makedirs(\"metrics\", exist_ok=True)\n",
        "\n",
        "    print(f\"Using model: {MODEL_NAME}\")\n",
        "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "    # Step 1: Load dataset\n",
        "    df = load_dataset()\n",
        "    num_labels = len(df['label'].unique())\n",
        "\n",
        "    # Step 2: Split dataset\n",
        "    X_train, X_val, y_train, y_val = split_dataset(df)\n",
        "\n",
        "    # Step 3: Create tokenized datasets\n",
        "    train_dataset, val_dataset, tokenizer = create_tokenized_datasets(\n",
        "        X_train, X_val, y_train, y_val, MODEL_NAME\n",
        "    )\n",
        "\n",
        "    # Step 4: Train model\n",
        "    trainer, model = train_model(\n",
        "        train_dataset, val_dataset, tokenizer, MODEL_NAME, OUTPUT_DIR, num_labels\n",
        "    )\n",
        "\n",
        "    # Step 5: Evaluate model\n",
        "    accuracy, report = evaluate_model(trainer, X_val, y_val, OUTPUT_DIR, num_labels)\n",
        "\n",
        "    # Step 6: Export to ONNX\n",
        "    onnx_success = export_to_onnx(OUTPUT_DIR, ONNX_PATH)\n",
        "\n",
        "    # Step 7: Export to TFLite\n",
        "    tflite_success = export_to_tflite_from_pt(OUTPUT_DIR, TFLITE_PATH)\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DistilBERT Tagalog Classification Training Complete!\")\n",
        "\n",
        "    if onnx_success:\n",
        "        print(f\"✅ ONNX model: {ONNX_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ ONNX export: FAILED\")\n",
        "\n",
        "    if tflite_success:\n",
        "        print(f\"✅ TFLite model: {TFLITE_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ TFLite export: FAILED\")\n",
        "\n",
        "    print(f\"\\nModel checkpoints: {OUTPUT_DIR}\")\n",
        "    print(f\"Metrics: metrics/distilbert_tagalog_metrics.txt\")\n",
        "    print(f\"Final validation accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "uhFj6s8R4x6z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INFERENCE"
      ],
      "metadata": {
        "id": "GJFb4SNi4zx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference(model_dir, test_texts=None):\n",
        "    if test_texts is None:\n",
        "        test_texts = [\n",
        "            # Positive sentiment\n",
        "            \"Napakaganda ng produktong ito, sulit na sulit!\",\n",
        "            \"Sobrang galing ng serbisyo nila, highly recommended!\",\n",
        "            \"Magandang kalidad at mabilis na delivery.\",\n",
        "            \"Napakahusay ng customer support, user-friendly pa.\",\n",
        "            \"Masarap ang pagkain dito, babalik ako ulit.\",\n",
        "\n",
        "            # Neutral sentiment\n",
        "            \"Okay lang ang produkto, walang masama.\",\n",
        "            \"Average lang ang kalidad, sakto sa presyo.\",\n",
        "            \"Gumagana naman, walang problema.\",\n",
        "            \"Standard features, typical sa price range na to.\",\n",
        "            \"Normal lang ang delivery time, okay naman.\",\n",
        "\n",
        "            # Negative sentiment\n",
        "            \"Sobrang pangit ng produkto, sayang ang pera.\",\n",
        "            \"Mababa ang kalidad, nasira agad after one day.\",\n",
        "            \"Napakasama ng customer service, worst ever.\",\n",
        "            \"Sobrang bagal ng delivery at sira pa ang packaging.\",\n",
        "            \"Hindi ko irerekumenda, very disappointing.\",\n",
        "        ]\n",
        "\n",
        "    print(\"\\nTesting trained DistilBERT Tagalog model...\")\n",
        "\n",
        "    try:\n",
        "        # Load model and tokenizer\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Determine label names based on number of labels\n",
        "        num_labels = model.config.num_labels\n",
        "        if num_labels == 2:\n",
        "            label_names = [\"Safe\", \"NSFW\"]\n",
        "        elif num_labels == 3:\n",
        "            label_names = [\"Positive\", \"Neutral\", \"Negative\"]\n",
        "        else:\n",
        "            label_names = [f\"Class_{i}\" for i in range(num_labels)]\n",
        "\n",
        "        for i, text in enumerate(test_texts):\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=256,\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "            # Predict\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "                predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "                confidence = predictions[0][predicted_class].item()\n",
        "\n",
        "            # Map predictions to labels\n",
        "            label = label_names[predicted_class] if predicted_class < len(label_names) else f\"Class_{predicted_class}\"\n",
        "\n",
        "            print(f\"Text {i+1}: '{text}'\")\n",
        "            print(f\"  -> {label} (confidence: {confidence:.4f})\")\n",
        "\n",
        "            # Show all probabilities\n",
        "            probs_str = \", \".join([f\"{label_names[j] if j < len(label_names) else f'Class_{j}'}={predictions[0][j].item():.3f}\"\n",
        "                                 for j in range(num_labels)])\n",
        "            print(f\"  Probabilities: {probs_str}\")\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Inference test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "FwjSKtnl42mB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROGRAM EXECUTION"
      ],
      "metadata": {
        "id": "ZVMcI-GH43fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run the main pipeline\n",
        "        main()\n",
        "\n",
        "        # Optional: Test inference\n",
        "        test_inference(\"models/distilbert_tagalog_classification\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nTraining interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\nProgram execution completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bb9c040512ee400486dc0b2265e8762e",
            "d3a398687ade406b843f36ad95bd837d",
            "89eee6d73a934ba1895451cde759548b",
            "d6d0fb8f78074441b4d9678697d6e036",
            "25526d04359645b686734b0a9fc820fd",
            "698ba11f760b4a14a0ebaac123efc9c1",
            "1874645353e04a1fbf11a38bf2e97b80",
            "b28ed321c05e4ceab04914672b7377d8",
            "9c6117b48860402db1e04c10527fd1b9",
            "2e48fb0be39b4545a60f50a1cea92b55",
            "a93fc20e25dd4ba3a9ac58f0d0b8fa01",
            "b0ba98681ff24d879c93adfc3b08278a",
            "9a98008eb7174b119cbe084b866bae5c",
            "ea6a0ca473e24569bde16cca65a4a072",
            "80e84a1fa75247ad86f3b5ecff53d9fb",
            "8ce0263a93f34d7c818c47c4100acd88",
            "a4697c0ef08548c18332c2661fd11e0e",
            "52b3cf0d7f594977b96c79c66f37e8d3",
            "e5ae539eec75494aab4fc5852ebcb47d",
            "d92d3c3001514be19e458219c1545d0f",
            "09c83b5b2c834eb68a3dfeb962104166",
            "01ad820092c34961aa7f8a7dfbc26abd"
          ]
        },
        "id": "y4val8Pi44go",
        "outputId": "f47b66b9-d8d8-434b-eed9-3c8fffcd98e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting DistilBERT Tagalog Text Classification Pipeline\n",
            "======================================================================\n",
            "Using model: jcblaise/distilbert-tagalog-base-cased\n",
            "Output directory: models/distilbert_tagalog_classification\n",
            "Loading dataset from dataset.csv...\n",
            "Dataset loaded successfully. Shape: (45, 2)\n",
            "Dataset validation complete. Clean shape: (45, 2)\n",
            "Number of classes: 3\n",
            "Label distribution:\n",
            "label\n",
            "0    15\n",
            "1    15\n",
            "2    15\n",
            "Name: count, dtype: int64\n",
            "Splitting dataset: 20.0% for validation...\n",
            "Training set: 36 samples\n",
            "Validation set: 9 samples\n",
            "Loading DistilBERT Tagalog tokenizer and creating tokenized datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb9c040512ee400486dc0b2265e8762e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0ba98681ff24d879c93adfc3b08278a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete!\n",
            "Sample tokenized text length: 14\n",
            "Initializing DistilBERT Tagalog model for classification training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at jcblaise/distilbert-tagalog-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1679934366.py:78: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:40, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.074002</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.738095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.085100</td>\n",
              "      <td>1.065864</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.641270</td>\n",
              "      <td>0.641270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.085100</td>\n",
              "      <td>1.061035</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.516667</td>\n",
              "      <td>0.516667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to models/distilbert_tagalog_classification...\n",
            "Evaluating model performance...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics saved to metrics/distilbert_tagalog_metrics.txt\n",
            "Validation Accuracy: 0.7778\n",
            "F1-Score (Macro): 0.7381\n",
            "Exporting DistilBERT Tagalog model to ONNX format...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2627031228.py:20: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model exported to: models/distilbert_tagalog_classification_model.onnx\n",
            "ONNX model size: 254.31 MB\n",
            "Converting DistilBERT Tagalog PyTorch model to TensorFlow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7de9bfe8bb30>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7de994102900>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7de9848ef260>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7de9848fc110>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7de9848fef30>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7de983a00a70>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved intermediate TensorFlow model to models/distilbert_tagalog_classification/tf_saved_model\n",
            "TFLite model successfully exported to: models/distilbert_tagalog_classification_model.tflite\n",
            "TFLite model size: 127.24 MB\n",
            "\n",
            "======================================================================\n",
            "DistilBERT Tagalog Classification Training Complete!\n",
            "✅ ONNX model: models/distilbert_tagalog_classification_model.onnx\n",
            "✅ TFLite model: models/distilbert_tagalog_classification_model.tflite\n",
            "\n",
            "Model checkpoints: models/distilbert_tagalog_classification\n",
            "Metrics: metrics/distilbert_tagalog_metrics.txt\n",
            "Final validation accuracy: 0.7778\n",
            "\n",
            "Testing trained DistilBERT Tagalog model...\n",
            "Text 1: 'Napakaganda ng produktong ito, sulit na sulit!'\n",
            "  -> Positive (confidence: 0.3451)\n",
            "  Probabilities: Positive=0.345, Neutral=0.322, Negative=0.333\n",
            "\n",
            "Text 2: 'Sobrang galing ng serbisyo nila, highly recommended!'\n",
            "  -> Positive (confidence: 0.3593)\n",
            "  Probabilities: Positive=0.359, Neutral=0.297, Negative=0.344\n",
            "\n",
            "Text 3: 'Magandang kalidad at mabilis na delivery.'\n",
            "  -> Positive (confidence: 0.3609)\n",
            "  Probabilities: Positive=0.361, Neutral=0.317, Negative=0.322\n",
            "\n",
            "Text 4: 'Napakahusay ng customer support, user-friendly pa.'\n",
            "  -> Negative (confidence: 0.3536)\n",
            "  Probabilities: Positive=0.336, Neutral=0.310, Negative=0.354\n",
            "\n",
            "Text 5: 'Masarap ang pagkain dito, babalik ako ulit.'\n",
            "  -> Positive (confidence: 0.3471)\n",
            "  Probabilities: Positive=0.347, Neutral=0.326, Negative=0.327\n",
            "\n",
            "Text 6: 'Okay lang ang produkto, walang masama.'\n",
            "  -> Neutral (confidence: 0.3540)\n",
            "  Probabilities: Positive=0.315, Neutral=0.354, Negative=0.331\n",
            "\n",
            "Text 7: 'Average lang ang kalidad, sakto sa presyo.'\n",
            "  -> Positive (confidence: 0.3405)\n",
            "  Probabilities: Positive=0.340, Neutral=0.333, Negative=0.327\n",
            "\n",
            "Text 8: 'Gumagana naman, walang problema.'\n",
            "  -> Neutral (confidence: 0.3426)\n",
            "  Probabilities: Positive=0.331, Neutral=0.343, Negative=0.327\n",
            "\n",
            "Text 9: 'Standard features, typical sa price range na to.'\n",
            "  -> Negative (confidence: 0.3416)\n",
            "  Probabilities: Positive=0.322, Neutral=0.336, Negative=0.342\n",
            "\n",
            "Text 10: 'Normal lang ang delivery time, okay naman.'\n",
            "  -> Negative (confidence: 0.3449)\n",
            "  Probabilities: Positive=0.327, Neutral=0.328, Negative=0.345\n",
            "\n",
            "Text 11: 'Sobrang pangit ng produkto, sayang ang pera.'\n",
            "  -> Negative (confidence: 0.3615)\n",
            "  Probabilities: Positive=0.328, Neutral=0.311, Negative=0.361\n",
            "\n",
            "Text 12: 'Mababa ang kalidad, nasira agad after one day.'\n",
            "  -> Negative (confidence: 0.3723)\n",
            "  Probabilities: Positive=0.332, Neutral=0.296, Negative=0.372\n",
            "\n",
            "Text 13: 'Napakasama ng customer service, worst ever.'\n",
            "  -> Positive (confidence: 0.3463)\n",
            "  Probabilities: Positive=0.346, Neutral=0.309, Negative=0.345\n",
            "\n",
            "Text 14: 'Sobrang bagal ng delivery at sira pa ang packaging.'\n",
            "  -> Positive (confidence: 0.3526)\n",
            "  Probabilities: Positive=0.353, Neutral=0.325, Negative=0.322\n",
            "\n",
            "Text 15: 'Hindi ko irerekumenda, very disappointing.'\n",
            "  -> Positive (confidence: 0.3564)\n",
            "  Probabilities: Positive=0.356, Neutral=0.318, Negative=0.326\n",
            "\n",
            "\n",
            "Program execution completed.\n"
          ]
        }
      ]
    }
  ]
}